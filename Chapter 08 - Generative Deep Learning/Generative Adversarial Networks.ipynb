{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks (GANs)\n",
    "\n",
    "Ara an alternative to VAEs for learning latent spaces of images. They enbale the generation of fairly realistic synthetic images by forcing the generated images to be statistically almost indistinguishable from real ones.\n",
    "\n",
    "An intuitive way to understand GANs is to imagine a forger trying to create a fake Picasso painting. At first, the forger is pretty bad at the task. He mixes some of his fakes with authentic Picassos and shows them all to an art dealer. The art dealer makes an authenticity assessement for each Picasso and gives feedback about what makes a Picasso look like a real Picasso. The forger goes to his studio to prepare more fakes. As time goes the forger becomes increasingly expert at imitating pictures, and the art dealer becomes increasingly expert spotting fakes\n",
    "\n",
    "A GAN is made of two parts:\n",
    "\n",
    "- *Generator network*: Takes as input a random vector (random point in the latent space), and decodes it into a synthetic image.\n",
    "\n",
    "- *Discriminator network (or adversary)*: Takes as input an image (real or fake), and predicts weather the image came from the training set or was created by the *generator*.\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1200/1*pHOkZ0HJrUSP827-fZFETg.png)\n",
    "\n",
    "## Schematic implementation of *Deep Convolutional GAN (DCGAN)*\n",
    "\n",
    "> In this example will be using the CIFAR-10 dataset\n",
    "\n",
    "1. A `generator` networks maps vectors of shape `(latent_dim, )` to images of shape `(32, 32, 3)`.\n",
    "\n",
    "2. A `discriminator` network maps images ti a binary score estimating the probability thet the image is real.\n",
    "\n",
    "3. A `gan` network chains the generator and the discriminator together: `gan(x) = discriminator(generator(x))`. Thus this `gan` maps latent space vector to the discriminator's assessement of the realism of this latent vectors as decoded by the generator.\n",
    "\n",
    "4. You train the discriminator using examples of real and fake images along with \"real\" / \"fake\" labels, just as you train any regular image-classification model.\n",
    "\n",
    "5. To train the generator, you use the gradients of the generator's weights with regard to the loss of the `gan` model. This means, at every step, you move the weights of the generator in a direction that makes the discriminator more likely to classify as real the images decoded by the generator. In other words, you train the generator to fool the discriminator.\n",
    "\n",
    "## GANs' tricks\n",
    "\n",
    "The process of training GANs adn tuning GAN implementation is difficult.\n",
    "\n",
    "- We use `tanh` as the activation in the generator, instead of `sigmoid`.\n",
    "- We sample points from the latent space using a *normal distribution*, not a uniform dits.\n",
    "- Stochasticity is good to introduce robustness. GANs are likely to stuck in all sort of ways, introducing randomness helps prevent this. We introduce randomness using dropout and adding noise to the labels for the discriminator.\n",
    "- Sparsisity is often a desirable property, but not in GANs. Two things can include gradient sparsisity: ReLU and max pooling. Insead of ReLU we will be using LeakyReLU which reduces sparsisity by allowing small negative numbers, and instead of max pooling will use convolutional strided layers.\n",
    "- In generted images, it's common to see checkerboards artifacts caused by unequal coverage of the picel space in the generator. To fix this, we use a kernel size that's diviseible by the stride size whenever we uses an strided convolutional layer.\n",
    "\n",
    "![Checkerboards](https://distill.pub/2016/deconv-checkerboard/thumbnail.jpg)\n",
    "\n",
    "## The generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "\n",
    "generator_input = layers.Input((latent_dim, ))\n",
    "\n",
    "# Generate a 16x16x128 feature map\n",
    "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((16, 16, 128))(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# Upscale to 32x32 using a conv2d transpose\n",
    "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# Produces 32 x 32 x 3 feature map (shape of CIFAR 10 image)\n",
    "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
    "\n",
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 6, 6, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "\n",
    "x = layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dropout(.4)(x)\n",
    "\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optimizer = keras.optimizers.RMSprop(\n",
    "                                            lr=0.0008,\n",
    "                                            clipvalue=1.,\n",
    "                                            decay=1e-8)\n",
    "\n",
    "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The adversarial network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = layers.Input(shape=(latent_dim, ))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to train DCGAN\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
